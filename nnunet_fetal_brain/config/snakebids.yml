bids_dir: '/path/to/bids_dir'
output_dir: '/path/to/output_dir'

#enable printing debug statements during parsing -- disable if generating dag visualization
debug: False

derivatives: True #will search in bids/derivatives if True; can also be path(s) to derivatives datasets

#list of analysis levels in the bids app 
analysis_levels: &analysis_levels
 - participant
  

#mapping from analysis_level to set of target rules or files
targets_by_analysis_level:
  participant:
    - ''  # if '', then the first rule is run

#this configures the pybids grabber - create an entry for each type of input you want to grab
# indexed by name of input
#   dictionary for each input is passed directly to pybids get()
#    https://bids-standard.github.io/pybids/generated/bids.layout.BIDSLayout.html#bids.layout.BIDSLayout.get

pybids_inputs:
  bold:
    filters:
      suffix: 'bold'
      extension: '.nii.gz'
      datatype: 'func'
    wildcards:
      - subject
      - session
      - acquisition
      - task
      - run
  mask:
    filters:
      suffix: 'bold'
      scope: 'derivatives'
      extension: '.nii.gz'
      datatype: 'func'
    wildcards:
      - subject
      - session
      - acquisition
      - task
      - run
   

#configuration for the command-line parameters to make available
# passed on the argparse add_argument()
parse_args:

#---  core BIDS-app options --- (do not modify below) 

  bids_dir:
    help: The directory with the input dataset formatted according 
          to the BIDS standard.

  output_dir:
    help: The directory where the output files 
          should be stored. If you are running group level analysis
          this folder should be prepopulated with the results of the
          participant level analysis.

  analysis_level: 
    help: Level of the analysis that will be performed. 
    choices: *analysis_levels

  --participant_label:
    help: The label(s) of the participant(s) that should be analyzed. The label 
          corresponds to sub-<participant_label> from the BIDS spec 
          (so it does not include "sub-"). If this parameter is not 
          provided all subjects should be analyzed. Multiple 
          participants can be specified with a space separated list.
    nargs: '+'

  --exclude_participant_label:
    help: The label(s) of the participant(s) that should be excluded. The label 
          corresponds to sub-<participant_label> from the BIDS spec 
          (so it does not include "sub-"). If this parameter is not 
          provided all subjects should be analyzed. Multiple 
          participants can be specified with a space separated list.
    nargs: '+'

  --derivatives:
    help: 'Path(s) to a derivatives dataset, for folder(s) that contains multiple derivatives datasets (default: %(default)s) '
    default: False
    nargs: '+'

 # custom command-line parameters can then be added, these will get added to the config
 # below is an example to override config['bet_frac']

#--- workflow specific configuration -- below is just an example:


#singularity containers
singularity:
    fsl: 'docker://brainlife/fsl/6.0.0'

use_downloaded: 'trainRutherford' #if this doesn't exist in download_model, then will train instead

download_model:
  trainS6S7S9:
    url: 'https://www.dropbox.com/s/sx7mnk1ojopjd37/trained_model.3d_fullres.Task102_fetal_brain_bold_trainS5to9.nnUNetTrainerV2.model_best.tar'
    tar: 'trained_model.3d_fullres.Task102_fetal_brain_bold_trainS5to9.nnUNetTrainerV2.model_best.tar'
    out: 'nnUNet/3d_fullres/Task102_fetal_brain_bold_trainS5to9/nnUNetTrainerV2__nnUNetPlansv2.1/fold_{fold}/model_best.model'
    checkpoint: 'model_best'
    unettask: 'Task102_fetal_brain_bold_trainS5to9'
    trained_on:
      - S6
      - S7
      - S9
  train6subj:
    url: 'https://www.dropbox.com/s/2hv2zher9humicr/trained_model.3d_fullres.Task103_fetal_brain_bold_train6subj.nnUNetTrainerV2.model_best.tar'
    tar: 'trained_model.3d_fullres.Task103_fetal_brain_bold_train6subj.nnUNetTrainerV2.model_best.tar'
    out: 'nnUNet/3d_fullres/Task103_fetal_brain_bold_train6subj/nnUNetTrainerV2__nnUNetPlansv2.1/fold_{fold}/model_best.model'
    checkpoint: 'model_best'
    unettask: 'Task103_fetal_brain_bold_train6subj'
    trained_on:
      - S1
      - S3
      - S6
      - S7
      - S9
      - S10
  trainRutherford:
    url: ''
    tar: 'trained_model.3d_fullres.Task104_fetal_brain_bold_trainRutherford.nnUNetTrainerV2.model_best.tar'
    out: 'nnUNet/3d_fullres/Task104_fetal_brain_bold_trainRutherford/nnUNetTrainerV2__nnUNetPlansv2.1/fold_{fold}/model_best.model'
    checkpoint: 'model_best'
    unettask: 'Task104_fetal_brain_bold_trainRutherford'

nnunet_env:
  nnUNet_raw_data_base: 'results'
  nnUNet_preprocessed: 'preprocessed'
  RESULTS_FOLDER: 'resources/trained_models'

nnunet_env_tmp:
  nnUNet_raw_data_base: 'results'
  nnUNet_preprocessed: '$SLURM_TMPDIR/preprocessed'
  RESULTS_FOLDER: 'resources/trained_models'



nnunet:
  trainer: 'nnUNetTrainerV2'
  arch: '3d_fullres'


 
train_subjects:
 - 2011
 - 2014
 - 2016
 - 2017
 - 2018
 - 2021
 - 2022
 - 2023
 - 2028
 - 2030
 - 2034
 - 2042
 - 2043
 - 2044
 - 2045
 - 2046
 - 2053
 - 2055
 - 2061
 - 2067
 - 2069
 - 2070
 - 2071
 - 2072
 - 2073
 - 2075
 - 2077
 - 2078
 - 2080
 - 2082
 - 2083
 - 2085
 - 2088
 - 2092
 - 2093
 - 2094
 - 2096
 - 2098
 - 2099
 - 2102
 - 2106
 - 2108
 - 2109
 - 2115
 - 2120
 - 2133
 - 2137
 - 2138
 - 2139
 - 2141
 - 2143
 - 2144
 - 2145
 - 2146
 - 2147
 - 2148
 - 2149
 - 2151
 - 2153
 - 2154
 - 2155
 - 2156
 - 2158
 - 2159
 - 2162
 - 2163
 - 2165
 - 2166
 - 2169
 - 2170
 - 2173
 - 2174
 - 2175
 - 2178
 - 2179
 - 2180
 - 2181
 - 2182
 - 2183
 - 2185
 - 2186
 - 2188
 - 2189
 - 2190
 - 2194
 - 2195
 - 2196
 - 2197
 - 2198
 - 2200
 - 2203
 - 2204
 - 2205
 - 2207
 - 2208
 - 2209
 - 2210
 - 2211
 - 2212
 - 2214
 - 2217
 - 2218
 - 2219
 - 2220
 - 2221
 - 2222
 - 2223
 - 2225
 - 2226
 - 2227
 - 2229
 - 2230

test_subjects:
 - 2006
 - 2013
 - 2019
 - 2020
 - 2029
 - 2031
 - 2033
 - 2035
 - 2037
 - 2040
 - 2041
 - 2047
 - 2048
 - 2051
 - 2052
 - 2057
 - 2063
 - 2065
 - 2066
 - 2074
 - 2076
 - 2079
 - 2081
 - 2084
 - 2086
 - 2091
 - 2095
 - 2100
 - 2101
 - 2103
 - 2105
 - 2107
 - 2117
 - 2136
 - 2142
 - 2150
 - 2152
 - 2157
 - 2160
 - 2161
 - 2164
 - 2168
 - 2176
 - 2177
 - 2191
 - 2192
 - 2206
 - 2228 
